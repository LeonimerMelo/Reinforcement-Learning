{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnTYiDaOqQiMGlunlkB9Tp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeonimerMelo/Reinforcement-Learning/blob/Reinforcement-Learning/Multi_Armed_Bandit_Problem_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Armed Bandit Problem\n",
        "O **Problema do Bandido Multibraço (Multi-Armed Bandit)** é um problema fundamental em **Aprendizado por Reforço (Reinforcement Learning)**, frequentemente usado para estudar o equilíbrio entre **exploração** e **exploração**. Ele envolve um agente que toma decisões (puxar as alavancas de um bandido) para maximizar a recompensa total ao longo do tempo.\n",
        "\n",
        "---\n",
        "\n",
        "### Configuração do Problema\n",
        "\n",
        "1. **Cenário**:\n",
        "   - Imagine uma máquina caça-níqueis (um \"bandido\") com $ n $ alavancas.\n",
        "   - Cada alavanca $ i $ fornece uma recompensa retirada de uma distribuição de probabilidade desconhecida com recompensa esperada $ \\mu_i $.\n",
        "\n",
        "2. **Objetivo**:\n",
        "   - Identificar a melhor alavanca (ou um conjunto de boas alavancas) que maximiza a recompensa esperada ao longo de $ T $ passos de tempo.\n",
        "\n",
        "3. **Dilema (Trade-Off)**:\n",
        "   - **Exploration**: Experimentar alavancas para coletar mais informações sobre suas recompensas.\n",
        "   - **Exploitation**: Escolher a alavanca que, com base nas informações anteriores, parece ser a melhor.\n",
        "\n",
        "---\n",
        "\n",
        "### Algoritmos para Resolver o Problema\n",
        "\n",
        "Diversos algoritmos foram desenvolvidos para lidar com o dilema exploração-exploração:\n",
        "\n",
        "#### 1. **Algoritmo ε-Greedy**\n",
        "   - Com probabilidade $ \\epsilon $, explora (escolhe uma alavanca aleatória).\n",
        "   - Com probabilidade $ 1 - \\epsilon $, explora (escolhe a alavanca com a maior recompensa estimada).\n",
        "\n",
        "  Pseudocódigo:\n",
        "  ```python\n",
        "  if random() < epsilon:\n",
        "      action = random_arm()\n",
        "  else:\n",
        "      action = arm_with_highest_estimated_reward()\n",
        "   ```\n",
        "\n",
        "#### 2. **UCB (Upper Confidence Bound)**\n",
        "   - Equilibra exploração e exploração usando um intervalo de confiança para cada alavanca.\n",
        "   - Escolhe a alavanca com o maior limite superior:\n",
        "     $$\n",
        "     a_t = \\arg\\max_i \\left( \\hat{\\mu}_i + \\sqrt{\\frac{2 \\ln t}{n_i}} \\right)\n",
        "     $$\n",
        "     Onde:\n",
        "     - $ \\hat{\\mu}_i $: Recompensa estimada da alavanca $ i $.\n",
        "     - $ n_i $: Número de vezes que a alavanca $ i $ foi escolhida.\n",
        "     - $ t $: Passo de tempo atual.\n",
        "\n",
        "#### 3. **Thompson Sampling**\n",
        "   - Uma abordagem Bayesiana para equilibrar exploração e exploração.\n",
        "   - Modela a recompensa de cada alavanca como uma distribuição de probabilidade e escolhe ações com base em amostras dessas distribuições.\n",
        "\n",
        "#### 4. **Seleção Softmax**\n",
        "   - Usa uma abordagem probabilística para escolher alavancas com base em suas recompensas estimadas.\n",
        "   - A probabilidade de escolher a alavanca $ i $ é proporcional a:\n",
        "$$P(i) = \\frac{e^{\\hat{\\mu}_i / \\tau}}{\\sum_{j}^{e^{\\hat{\\mu}_i / \\tau}}}$$\n",
        "Onde $\\tau$ (temperatura) controla o equilíbrio entre *exploration-exploitation trade-off*.\n",
        "\n",
        "---\n",
        "\n",
        "### Exemplo em Python: Algoritmo ε-Greedy\n",
        "\n",
        "Aqui está uma implementação básica do algoritmo **ε-Greedy**:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Configuração\n",
        "num_arms = 5\n",
        "num_steps = 1000\n",
        "true_rewards = np.random.rand(num_arms)  # Recompensas verdadeiras para cada alavanca\n",
        "epsilon = 0.1  # Taxa de exploração\n",
        "\n",
        "# Inicialização\n",
        "estimated_rewards = np.zeros(num_arms)  # Recompensas estimadas\n",
        "counts = np.zeros(num_arms)  # Número de vezes que cada alavanca foi escolhida\n",
        "total_reward = 0\n",
        "\n",
        "# Simulação\n",
        "for t in range(num_steps):\n",
        "    if np.random.rand() < epsilon:\n",
        "        # Explorar: Escolher uma alavanca aleatória\n",
        "        arm = np.random.randint(num_arms)\n",
        "    else:\n",
        "        # Explorar: Escolher a alavanca com a maior recompensa estimada\n",
        "        arm = np.argmax(estimated_rewards)\n",
        "    \n",
        "    # Puxar a alavanca escolhida\n",
        "    reward = np.random.rand() < true_rewards[arm]  # Recompensa binária simulada (0 ou 1)\n",
        "    \n",
        "    # Atualizar estimativas\n",
        "    counts[arm] += 1\n",
        "    estimated_rewards[arm] += (reward - estimated_rewards[arm]) / counts[arm]\n",
        "    \n",
        "    # Atualizar recompensa total\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"Recompensa Total: {total_reward}\")\n",
        "print(f\"Recompensas Verdadeiras: {true_rewards}\")\n",
        "print(f\"Recompensas Estimadas: {estimated_rewards}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Métricas-Chave\n",
        "\n",
        "1. **Regret (Arrependimento)**:\n",
        "   - Mede a perda causada por não escolher sempre a melhor alavanca.\n",
        "   - $ R(T) = T \\cdot \\mu^* - \\sum_{t=1}^T \\mu_{a_t} $\n",
        "     - $ \\mu^* $: Recompensa esperada da melhor alavanca.\n",
        "     - $ \\mu_{a_t} $: Recompensa esperada da alavanca escolhida no tempo $ t $.\n",
        "\n",
        "2. **Recompensa Cumulativa**:\n",
        "   - Recompensa total obtida ao longo de $ T $ passos de tempo.\n",
        "\n",
        "---\n",
        "\n",
        "### Aplicações\n",
        "\n",
        "1. **Sistemas de Recomendação**:\n",
        "   - Sugerir itens com base nas preferências do usuário (e.g., filmes, produtos).\n",
        "\n",
        "2. **Ensaios Clínicos**:\n",
        "   - Testar diferentes tratamentos enquanto maximiza os resultados dos pacientes.\n",
        "\n",
        "3. **Publicidade Online**:\n",
        "   - Escolher anúncios que maximizem a taxa de cliques.\n",
        "\n",
        "4. **IA para Jogos**:\n",
        "   - Equilibrar exploração e exploração em tomadas de decisão estratégicas.\n",
        "\n",
        "O **Problema do Bandido Multibraço** é um modelo simples, mas poderoso, que serve como ponto de partida para entender problemas mais complexos no aprendizado por reforço!"
      ],
      "metadata": {
        "id": "yOgAxV2WYLJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1d9hu840vJZME9rJhJQJpBC6hFYt7zgtB' width=700>"
      ],
      "metadata": {
        "id": "hWtPFyKJrbTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Setup\n",
        "num_arms = 5\n",
        "num_steps = 1000\n",
        "np.random.seed(10)\n",
        "true_rewards = np.random.rand(num_arms)  # True reward probabilities for each arm\n",
        "epsilon = 0.2  # Exploration rate\n",
        "\n",
        "# Initialization\n",
        "estimated_rewards = np.zeros(num_arms)  # Estimated rewards for each arm\n",
        "counts = np.zeros(num_arms)  # Number of times each arm was pulled\n",
        "total_reward = 0\n",
        "rwds = [0]\n",
        "# Simulation\n",
        "for t in range(num_steps):\n",
        "    if np.random.rand() < epsilon:\n",
        "        # Explore: Choose a random arm\n",
        "        arm = np.random.randint(num_arms)\n",
        "    else:\n",
        "        # Exploit: Choose the arm with the highest estimated reward\n",
        "        arm = np.argmax(estimated_rewards)\n",
        "\n",
        "    # Pull the chosen arm\n",
        "    reward = np.random.rand() < true_rewards[arm]  # Simulated binary reward (0 or 1)\n",
        "\n",
        "    # Update estimates\n",
        "    counts[arm] += 1\n",
        "    estimated_rewards[arm] += (reward - estimated_rewards[arm]) / counts[arm]\n",
        "\n",
        "    # Update total reward\n",
        "    total_reward += reward\n",
        "    rwds.append(np.mean(estimated_rewards))\n",
        "\n",
        "# print(f\"Total Reward: {total_reward}\")\n",
        "# print(f\"True Rewards: {true_rewards}\")\n",
        "# print(f\"Estimated Rewards: {estimated_rewards}\")\n",
        "\n",
        "# Resultados\n",
        "print(\"Probabilidades Reais: \", true_rewards)\n",
        "print(\"Recompensas Estimadas: \", estimated_rewards)\n",
        "print(\"Seleções por Alavanca: \", counts)\n",
        "print(\"Recompensa Cumulativa Total: \", total_reward)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axNZPihqcRtH",
        "outputId": "455c6aea-0597-4baa-8410-8c7016b990fc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilidades Reais:  [0.77132064 0.02075195 0.63364823 0.74880388 0.49850701]\n",
            "Recompensas Estimadas:  [0.78494624 0.06666667 0.72340426 0.77142857 0.53846154]\n",
            "Seleções por Alavanca:  [744.  30.  47. 140.  39.]\n",
            "Recompensa Cumulativa Total:  749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(rwds)\n",
        "plt.title('Average rewards')\n",
        "plt.xlabel('time steps')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "G37q1HIDoBV1",
        "outputId": "7863f328-1b41-4c22-895b-d7f2fd4bf36f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Atualizar a estimativa de recompensa\n",
        "\n",
        "```python\n",
        "# Update estimates\n",
        "counts[arm] += 1\n",
        "estimated_rewards[arm] += (reward - estimated_rewards[arm]) / counts[arm]\n",
        "\n",
        "```\n",
        "Esta parte do código é responsável por **atualizar a estimativa de recompensa média** para a alavanca escolhida com base no novo resultado obtido (recompensa). Vamos detalhar cada linha:\n",
        "\n",
        "---\n",
        "\n",
        "### Linha 1: `counts[arm] += 1`\n",
        "\n",
        "- **O que faz:** Incrementa o contador de quantas vezes a alavanca $ arm $ foi puxada.\n",
        "- **Por que é necessário:**\n",
        "  - Para calcular a média incremental, precisamos saber o número total de vezes que a alavanca foi escolhida.\n",
        "  - Esse valor será usado no cálculo da nova média.\n",
        "\n",
        "Exemplo:\n",
        "- Se a alavanca $ 2 $ foi puxada 3 vezes anteriormente, após esta linha, o contador será atualizado para 4.\n",
        "\n",
        "---\n",
        "\n",
        "### Linha 2: `estimated_rewards[arm] += (reward - estimated_rewards[arm]) / counts[arm]`\n",
        "\n",
        "Essa linha usa a **fórmula de atualização incremental da média** para ajustar a recompensa estimada ($ \\hat{\\mu}_i $) da alavanca $ arm $ com base na nova recompensa $ reward $.\n",
        "\n",
        "#### **Fórmula de Atualização Incremental**\n",
        "A fórmula básica da média é:\n",
        "$$\n",
        "\\hat{\\mu}_i = \\frac{\\text{soma dos valores observados}}{\\text{número de observações}}\n",
        "$$\n",
        "No entanto, recalcular a soma de todos os valores observados a cada atualização é ineficiente. Em vez disso, usamos uma fórmula incremental para atualizar a média sem precisar armazenar todas as recompensas anteriores:\n",
        "\n",
        "$$\n",
        "\\hat{\\mu}_i \\gets \\hat{\\mu}_i + \\frac{\\text{(nova recompensa - média atual)}}{\\text{número de vezes que a alavanca foi puxada}}\n",
        "$$\n",
        "\n",
        "- **Parte 1:** $(\\text{reward} - \\text{estimated_rewards[arm]})$\n",
        "  - Calcula a diferença entre a recompensa recém-obtida ($ reward $) e a recompensa média atual estimada ($ \\text{estimated_rewards[arm]} $).\n",
        "  - Essa diferença indica o quanto o novo valor difere da média atual.\n",
        "\n",
        "- **Parte 2:** $(\\text{reward} - \\text{estimated_rewards[arm]}) / \\text{counts[arm]}$\n",
        "  - Ajusta a diferença pelo número total de vezes que a alavanca foi puxada.\n",
        "  - Isso garante que a média seja alterada de forma gradual e proporcional à quantidade de dados já observados.\n",
        "\n",
        "- **Parte 3:** `estimated_rewards[arm] += ...`\n",
        "  - Atualiza a recompensa média incrementalmente, incorporando a nova observação.\n",
        "\n",
        "#### Exemplo Prático:\n",
        "Imagine que:\n",
        "- A recompensa estimada atual para a alavanca $ 2 $ seja $ \\hat{\\mu}_2 = 0.5 $,\n",
        "- Essa alavanca foi puxada 4 vezes,\n",
        "- A nova recompensa obtida ($ reward $) seja $ 1.0 $.\n",
        "\n",
        "1. **Atualizar o contador**:\n",
        "   $$\n",
        "   \\text{counts[2]} \\gets 5\n",
        "   $$\n",
        "\n",
        "2. **Calcular a diferença entre a nova recompensa e a média atual**:\n",
        "   $$\n",
        "   \\text{(reward - estimated_rewards[2])} = 1.0 - 0.5 = 0.5\n",
        "   $$\n",
        "\n",
        "3. **Atualizar a média**:\n",
        "   $$\n",
        "   \\text{estimated_rewards[2]} \\gets 0.5 + \\frac{0.5}{5} = 0.5 + 0.1 = 0.6\n",
        "   $$\n",
        "\n",
        "Agora, a recompensa média estimada para a alavanca $ 2 $ foi ajustada para $ 0.6 $, levando em consideração a nova observação.\n",
        "\n",
        "---\n",
        "\n",
        "### Por que usar a fórmula incremental?\n",
        "\n",
        "1. **Eficiência Computacional**:\n",
        "   - Não precisamos armazenar todas as recompensas passadas para recalcular a média.\n",
        "   - Apenas o valor atual da média e o número de observações são suficientes.\n",
        "\n",
        "2. **Atualização Dinâmica**:\n",
        "   - Cada nova recompensa tem menos impacto na média à medida que o número de observações aumenta, o que reflete melhor a confiança na estimativa.\n",
        "\n",
        "---\n",
        "\n",
        "### Resumo\n",
        "Essa fórmula de atualização é uma maneira elegante e eficiente de calcular a média incrementalmente, permitindo que o algoritmo ajuste continuamente sua estimativa de recompensa com base em novos dados. É especialmente útil em problemas como o bandido multibraço, onde as recompensas são observadas progressivamente."
      ],
      "metadata": {
        "id": "_9YuyHol9vjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Passoa a passo"
      ],
      "metadata": {
        "id": "FtoLytlDDnn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimated_rewards = np.zeros(num_arms)  # Estimated rewards for each arm\n",
        "counts = np.zeros(num_arms)  # Number of times each arm was pulled\n",
        "total_reward = 0\n",
        "print(estimated_rewards)\n",
        "print(counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vwxPDeA5qzj",
        "outputId": "b1feae9a-63cf-4122-9969-b2c4e62629e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_rewards = np.random.rand(num_arms)\n",
        "true_rewards"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfIddsyP6dxB",
        "outputId": "85d924ac-6ac0-4450-fee4-e5653ca548e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.41762441, 0.7373844 , 0.91337874, 0.34114791, 0.55892045])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvnMI2C956ny",
        "outputId": "b855281b-15b1-406c-a9c3-7ab07cd85689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Começa o loop:"
      ],
      "metadata": {
        "id": "6t8VHpNa6rlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.random.rand()\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFugniQZ5zFJ",
        "outputId": "6088e553-4453-4254-c973-627ab48f71a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1811683077412788"
            ]
          },
          "metadata": {},
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if c < epsilon:\n",
        "    # Explore: Choose a random arm\n",
        "    arm = np.random.randint(num_arms)\n",
        "    print('exploration')\n",
        "else:\n",
        "    # Exploit: Choose the arm with the highest estimated reward\n",
        "    arm = np.argmax(estimated_rewards)\n",
        "    print('exploitation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRLWKQ765udx",
        "outputId": "156318b4-ff9f-4719-ba10-a1ad5d4b4815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exploration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB6SQYqC24za",
        "outputId": "51fe68fa-9ced-4edb-d001-b99751988d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_rewards[arm]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQ9QCApd20Ii",
        "outputId": "08a4e484-9d60-4480-efd5-7c9460f4548c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34114790713481635"
            ]
          },
          "metadata": {},
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = np.random.rand()\n",
        "r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTRHQnOM3Gb6",
        "outputId": "c70b43ef-c1d5-48ec-9da9-36bb5763fc2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17470270334649896"
            ]
          },
          "metadata": {},
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pull the chosen arm and receve the reward (or not!)\n",
        "reward = r < true_rewards[arm]\n",
        "# reward is binary: True (=1) or False (=0)\n",
        "reward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu2Ix7XL3Nvs",
        "outputId": "94f7bdd5-96d1-476d-f5d6-a3ad7960865e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts[arm] += 1\n",
        "counts[arm]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k_KAHej3prD",
        "outputId": "c734fe1c-4df8-41b3-8b0d-45fe100c3541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0"
            ]
          },
          "metadata": {},
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIsl78Pz8q1r",
        "outputId": "d519cbe3-655a-430c-d124-285eeb1a6220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 0., 4., 5., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimated_rewards"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YET_mjvK8-3Q",
        "outputId": "4f4e0109-dec1-4400-a6b3-9a870ebc9720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0. , 0. , 1. , 0.5, 0. ])"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e = estimated_rewards[arm]\n",
        "e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MH58jkw4HlE",
        "outputId": "69742e5f-1b57-4ee1-ab3b-b162dc505240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcula a diferença entre a recompensa recém-obtida (reward) e a recompensa média atual estimada\n",
        "a = reward - e\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvniCVPT30ia",
        "outputId": "f70a1a9f-b0a1-4e3d-caf3-0b30612265e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajusta a diferença pelo número total de vezes que a alavanca foi puxada\n",
        "b = a / counts[arm]\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6riAc7c4456",
        "outputId": "03ce5706-5957-4e42-8d39-3ac4dd3e83ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1"
            ]
          },
          "metadata": {},
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Atualiza a recompensa média incrementalmente\n",
        "estimated_rewards[arm] = estimated_rewards[arm] + b\n",
        "estimated_rewards[arm]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFK-C28J5HFC",
        "outputId": "7bb5c733-cfd9-471f-adac-abeebcb1af9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6"
            ]
          },
          "metadata": {},
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_reward += reward\n",
        "total_reward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZy1B7AV5Tb7",
        "outputId": "537f994e-37a0-4827-edda-0dbc5a4a5cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retorna ao loop"
      ],
      "metadata": {
        "id": "Ikubt1Fc7h7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo de Recompensa Cumulativa no Problema do Bandido Multibraço\n",
        "\n",
        "A **recompensa cumulativa** é a soma das recompensas obtidas ao longo de vários passos de tempo. Vamos construir um exemplo prático baseado no algoritmo **ε-Greedy** para calcular a recompensa cumulativa ao final de uma simulação.\n",
        "\n",
        "---\n",
        "\n",
        "### Código: Calculando Recompensa Cumulativa\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Configuração\n",
        "num_arms = 3  # Número de alavancas\n",
        "num_steps = 100  # Número de passos\n",
        "true_rewards = [0.2, 0.5, 0.8]  # Probabilidades reais de recompensa para cada alavanca\n",
        "epsilon = 0.1  # Taxa de exploração\n",
        "\n",
        "# Inicialização\n",
        "estimated_rewards = np.zeros(num_arms)  # Recompensas estimadas\n",
        "counts = np.zeros(num_arms)  # Contador de seleções por alavanca\n",
        "total_reward = 0  # Recompensa cumulativa inicial\n",
        "\n",
        "# Simulação\n",
        "for step in range(num_steps):\n",
        "    # Escolher alavanca: Explorar ou Explorar\n",
        "    if np.random.rand() < epsilon:\n",
        "        arm = np.random.randint(num_arms)  # Escolher alavanca aleatória (explorar)\n",
        "    else:\n",
        "        arm = np.argmax(estimated_rewards)  # Escolher alavanca com maior recompensa estimada (explorar)\n",
        "    \n",
        "    # Puxar a alavanca escolhida e obter recompensa\n",
        "    reward = np.random.rand() < true_rewards[arm]  # Simula recompensa (0 ou 1)\n",
        "    \n",
        "    # Atualizar estimativas\n",
        "    counts[arm] += 1\n",
        "    estimated_rewards[arm] += (reward - estimated_rewards[arm]) / counts[arm]\n",
        "    \n",
        "    # Atualizar recompensa cumulativa\n",
        "    total_reward += reward\n",
        "\n",
        "# Resultados\n",
        "print(\"Probabilidades Reais: \", true_rewards)\n",
        "print(\"Recompensas Estimadas: \", estimated_rewards)\n",
        "print(\"Seleções por Alavanca: \", counts)\n",
        "print(\"Recompensa Cumulativa Total: \", total_reward)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Saída Exemplo (simulada)\n",
        "\n",
        "Após executar o código acima, você pode obter algo como:\n",
        "\n",
        "```plaintext\n",
        "Probabilidades Reais:  [0.2, 0.5, 0.8]\n",
        "Recompensas Estimadas:  [0.18, 0.52, 0.76]\n",
        "Seleções por Alavanca:  [10, 30, 60]\n",
        "Recompensa Cumulativa Total:  68\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Explicação dos Resultados\n",
        "\n",
        "1. **Recompensas Verdadeiras**:\n",
        "   - A probabilidade real de cada alavanca fornecer uma recompensa (exemplo: 20%, 50%, e 80%).\n",
        "\n",
        "2. **Recompensas Estimadas**:\n",
        "   - As estimativas calculadas pelo agente com base nas interações.\n",
        "\n",
        "3. **Seleções por Alavanca**:\n",
        "   - Quantas vezes cada alavanca foi puxada.\n",
        "\n",
        "4. **Recompensa Cumulativa Total**:\n",
        "   - A soma de todas as recompensas obtidas durante os $ num\\_steps $.\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretação da Recompensa Cumulativa\n",
        "\n",
        "- Quanto mais o algoritmo consegue explorar as alavancas certas (com maior probabilidade de recompensa), maior será a **recompensa cumulativa**.\n",
        "- No exemplo, a alavanca com 80% de probabilidade de recompensa foi puxada com mais frequência, resultando em uma alta recompensa total.\n",
        "\n",
        "Este exemplo ilustra como o conceito de **recompensa cumulativa** mede o sucesso do agente ao equilibrar exploração e exploração no problema do bandido multibraço!"
      ],
      "metadata": {
        "id": "KHdBTI3UgD8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Configuração\n",
        "num_arms = 3  # Número de alavancas\n",
        "num_steps = 100  # Número de passos\n",
        "true_rewards = [0.2, 0.5, 0.8]  # Probabilidades reais de recompensa para cada alavanca\n",
        "epsilon = 0.1  # Taxa de exploração\n",
        "\n",
        "# Inicialização\n",
        "estimated_rewards = np.zeros(num_arms)  # Recompensas estimadas\n",
        "counts = np.zeros(num_arms)  # Contador de seleções por alavanca\n",
        "total_reward = 0  # Recompensa cumulativa inicial\n",
        "\n",
        "# Simulação\n",
        "for step in range(num_steps):\n",
        "    # Escolher alavanca: Explorar ou Explorar\n",
        "    if np.random.rand() < epsilon:\n",
        "        arm = np.random.randint(num_arms)  # Escolher alavanca aleatória (explorar)\n",
        "    else:\n",
        "        arm = np.argmax(estimated_rewards)  # Escolher alavanca com maior recompensa estimada (explorar)\n",
        "\n",
        "    # Puxar a alavanca escolhida e obter recompensa\n",
        "    reward = np.random.rand() < true_rewards[arm]  # Simula recompensa (0 ou 1)\n",
        "\n",
        "    # Atualizar estimativas\n",
        "    counts[arm] += 1\n",
        "    estimated_rewards[arm] += (reward - estimated_rewards[arm]) / counts[arm]\n",
        "\n",
        "    # Atualizar recompensa cumulativa\n",
        "    total_reward += reward\n",
        "\n",
        "# Resultados\n",
        "print(\"Probabilidades Reais: \", true_rewards)\n",
        "print(\"Recompensas Estimadas: \", estimated_rewards)\n",
        "print(\"Seleções por Alavanca: \", counts)\n",
        "print(\"Recompensa Cumulativa Total: \", total_reward)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wEn8deOgXf7",
        "outputId": "3996cb73-6ae1-4057-db2e-ade37b0b7be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilidades Reais:  [0.2, 0.5, 0.8]\n",
            "Recompensas Estimadas:  [0.25  0.375 0.25 ]\n",
            "Seleções por Alavanca:  [88.  8.  4.]\n",
            "Recompensa Cumulativa Total:  26\n"
          ]
        }
      ]
    }
  ]
}